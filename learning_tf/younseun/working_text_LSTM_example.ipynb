{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h': 0, 'd': 1, 'i': 2, 'y': 3, 'l': 4, 'f': 5, 'o': 6, 'b': 7, ' ': 8, 'p': 9, 'u': 10, 'n': 11, 's': 12, 'a': 13, 't': 14, 'w': 15} {0: 'h', 1: 'd', 2: 'i', 3: 'y', 4: 'l', 5: 'f', 6: 'o', 7: 'b', 8: ' ', 9: 'p', 10: 'u', 11: 'n', 12: 's', 13: 'a', 14: 't', 15: 'w'}\n"
     ]
    }
   ],
   "source": [
    "sample = ' if you want you build a ship'\n",
    "sample_set = list(set(sample))\n",
    "char2idx = {c : i for i, c in enumerate(sample_set)}\n",
    "idx2char = {i : c for i, c in enumerate(sample_set)}\n",
    "print(char2idx,idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 16, 1, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper parameters\n",
    "dic_size = len(char2idx)\n",
    "rnn_hidden_size = len(char2idx)\n",
    "num_classes = len(char2idx)\n",
    "batch_size = 1\n",
    "sequence_length = len(sample) -1\n",
    "dic_size, rnn_hidden_size, num_classes, batch_size, sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = [char2idx[c] for c in sample]\n",
    "x_data = [sample_index[:-1]]\n",
    "y_data = [sample_index[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sample = 'if  build you want ship you a'\n",
    "prediction_sample_index = [char2idx[c] for c in prediction_sample]\n",
    "prediction_data = [prediction_sample_index[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([8, 2, 5, 8, 3], [2, 5, 8, 3, 6], [2, 5, 8, 8, 7])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0][:5], y_data[0][:5], prediction_data[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, shape=[None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, shape=[None, sequence_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"one_hot_2:0\", shape=(?, 28, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X_one_hot = tf.one_hot(X, len(sample_set))\n",
    "print(X_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "with tf.variable_scope(\"lstm_kernel\", reuse=tf.AUTO_REUSE):\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 2.776608 prediction: inppaaaataataaaattattnna  aa\n",
      "100 loss: 2.6274922 prediction:                             \n",
      "200 loss: 2.5524058 prediction:                             \n",
      "300 loss: 2.465875 prediction:                             \n",
      "400 loss: 2.370521 prediction:                             \n",
      "500 loss: 2.2953103 prediction:                        i   i\n",
      "600 loss: 2.2231362 prediction:                             \n",
      "700 loss: 2.1474636 prediction:                             \n",
      "800 loss: 2.0513408 prediction: f                           \n",
      "900 loss: 1.9903233 prediction: f                           \n",
      "1000 loss: 1.9331586 prediction: f                           \n",
      "1100 loss: 1.8880283 prediction: f                 u         \n",
      "1200 loss: 1.8500211 prediction: f y               uu        \n",
      "1300 loss: 1.8194603 prediction: f y               uuu       \n",
      "1400 loss: 1.793905 prediction: f yy              uuuu i    \n",
      "1500 loss: 1.7716563 prediction: f yy              uuuu i    \n",
      "1600 loss: 1.7521662 prediction: f yy              uuuu i    \n",
      "1700 loss: 1.7349867 prediction: f yy              uuuuuii   \n",
      "1800 loss: 1.7197133 prediction: f yy   a          uuuuuii   \n",
      "1900 loss: 1.706018 prediction: f yy   a          uuuu ii   \n",
      "2000 loss: 1.6936182 prediction: f yy   a        o uuuu ii  i\n",
      "2100 loss: 1.6823426 prediction: f yy   a        o uuuu i   i\n",
      "2200 loss: 1.6715676 prediction: f yy  aa     y  o uuuu i   i\n",
      "2300 loss: 1.6630977 prediction: f yy  aa        o uuuuii   i\n",
      "2400 loss: 1.6502845 prediction: f yy  aa     y  o uuuu i   i\n",
      "2500 loss: 1.6393602 prediction: f yy  aa     y  o uuu  i   i\n",
      "2600 loss: 1.6316077 prediction: f yy  aa     y    uuu  i    \n",
      "2700 loss: 1.621075 prediction: f yy  aa     yo   uubili    \n",
      "2800 loss: 1.6130525 prediction: f yy  aa     yo   uubili   a\n",
      "2900 loss: 1.606384 prediction: f yy  aa     yo u uuui i    \n",
      "3000 loss: 1.5991625 prediction: f yyu aa     yo u uubili   a\n",
      "3100 loss: 1.5922419 prediction: f yyu aa     yo   uubi     a\n",
      "3200 loss: 1.5868083 prediction: f yyu aa     yo   uubi     a\n",
      "3300 loss: 1.5805204 prediction: f yyu aa     yo u ubbll    a\n",
      "3400 loss: 1.5744549 prediction: f yyu aa     oo   bbill    a\n",
      "3500 loss: 1.5693605 prediction: f yyu aa     yo u bbill    a\n",
      "3600 loss: 1.564403 prediction: f yyu aa     oo   bbill    a\n",
      "3700 loss: 1.5599087 prediction: f yyu aa     oo u bbill    a\n",
      "3800 loss: 1.5555775 prediction: f yyu aa   y ou   bbill    a\n",
      "3900 loss: 1.5514435 prediction: f yyu aa t y ou   bbill    a\n",
      "4000 loss: 1.5478216 prediction: f yyu aa t y ou   bbill    a\n",
      "4100 loss: 1.5445397 prediction: f yyu aa t y ou   bbill    a\n",
      "4200 loss: 1.5410615 prediction: f yyu aa t y ou   bbill    a\n",
      "4300 loss: 1.5376273 prediction: f yyu aa t y ou   bbill    a\n",
      "4400 loss: 1.534444 prediction: f yyu aa t y ou   bbill    a\n",
      "4500 loss: 1.531614 prediction: f yyu aa t y ou u bbill  a a\n",
      "4600 loss: 1.5287789 prediction: f yyu aa t y ou   bbill    a\n",
      "4700 loss: 1.5260444 prediction: f yyu aa t y ou   bbill    a\n",
      "4800 loss: 1.5235267 prediction: f yyu aa t y ou u bbill  a a\n",
      "4900 loss: 1.5211557 prediction: f yyu aa t y ou u bbill  a a\n",
      "5000 loss: 1.5186017 prediction: f yyu aa t y ou   bbill  a a\n",
      "5100 loss: 1.5166137 prediction: f yyu aa t y ou u bbill    a\n",
      "5200 loss: 1.514298 prediction: f yyu aa t y ou u bbill  a a\n",
      "5300 loss: 1.5121987 prediction: f yyu aa t y ou u bbill    a\n",
      "5400 loss: 1.5101848 prediction: f yyu aa t y ou u bbill    a\n",
      "5500 loss: 1.5082439 prediction: f yyu aa t y ou u bbill    a\n",
      "5600 loss: 1.5063672 prediction: f yyu aa t y ou u bbill    a\n",
      "5700 loss: 1.5045542 prediction: f yyu aa t y ou u bbill    a\n",
      "5800 loss: 1.5028025 prediction: f yyu aa t y ou u bbill    a\n",
      "5900 loss: 1.5011085 prediction: f yyu aa t y ou u bbbll    a\n",
      "6000 loss: 1.4994674 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6100 loss: 1.4978784 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6200 loss: 1.4963393 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6300 loss: 1.494847 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6400 loss: 1.4933999 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6500 loss: 1.4919953 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6600 loss: 1.4906322 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6700 loss: 1.4893081 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6800 loss: 1.4880217 prediction: f yyu aa t y ouuu bbbll    a\n",
      "6900 loss: 1.4867713 prediction: f yyu aa t y ouuu bbbil    a\n",
      "7000 loss: 1.4855555 prediction: f yyu aa t y ouuu bbbil    a\n",
      "7100 loss: 1.4843726 prediction: f yyu aa t y ouuu bbbil    a\n",
      "7200 loss: 1.4832213 prediction: f yyu aa t y yuuu bbbil    a\n",
      "7300 loss: 1.4821002 prediction: f yyu aa t y yuuu bbbil    a\n",
      "7400 loss: 1.4810082 prediction: f yyu aa t y yuuu bbbil    a\n",
      "7500 loss: 1.479944 prediction: f yyu aa t y yuuu bbbil    a\n",
      "7600 loss: 1.4789065 prediction: f yyu aa t yyyuuu bbbili   a\n",
      "7700 loss: 1.4778947 prediction: f yyu aa t yyyouu bbbili   a\n",
      "7800 loss: 1.4769071 prediction: f yyu aa t yyyouu bbbili   a\n",
      "7900 loss: 1.4759432 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8000 loss: 1.475002 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8100 loss: 1.4740825 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8200 loss: 1.473184 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8300 loss: 1.4723054 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8400 loss: 1.4714463 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8500 loss: 1.4706055 prediction: f yyu aa t yyyouu bbbili   a\n",
      "8600 loss: 1.469783 prediction: f yyu aa t yyyouu bbuili   a\n",
      "8700 loss: 1.4689775 prediction: f yyu aa t yyyouu bbuili   a\n",
      "8800 loss: 1.4681886 prediction: f yyu aa t yyyouu bbuili   a\n",
      "8900 loss: 1.4674157 prediction: f yyu aa ttyyyouu bbuili   a\n",
      "9000 loss: 1.4666584 prediction: f yyu aa ttyyyouu bbuili   a\n",
      "9100 loss: 1.465916 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9200 loss: 1.4651881 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9300 loss: 1.464474 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9400 loss: 1.4637735 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9500 loss: 1.4630862 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9600 loss: 1.4624116 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9700 loss: 1.461749 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9800 loss: 1.4610986 prediction: f yyo aa ttyyyouu bbuili   a\n",
      "9900 loss: 1.4604596 prediction: f yyo aa ttyyyouu bbuili   a\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        l, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if i % 100 == 0:\n",
    "            result = sess.run(prediction, feed_dict={X:prediction_data})\n",
    "            result_str=[idx2char[c] for c in np.squeeze(result)]\n",
    "            print(i, \"loss:\", l, \"prediction:\", ''.join(result_str))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sample = 'if  build you want ship you a'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
