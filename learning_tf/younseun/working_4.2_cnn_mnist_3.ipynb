{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from layers import conv_layer, max_pool_2x2, full_layer\n",
    "from layers_0 import conv_layer_0, max_pool_2x2_0, full_layer_0\n",
    "from layers_3 import conv_layer_3, max_pool_2x2_3, full_layer_3\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/tmp/data'\n",
    "MINIBATCH_SIZE = 50\n",
    "STEPS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-263d54db0205>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# mnist[0]은 이미지, mnist[1]은 숫자값 ont Hot\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-73330f683a63>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "conv1 = conv_layer_3(x_image, shape=[5, 5, 1, 32])\n",
    "conv1_pool = max_pool_2x2_3(conv1)\n",
    "\n",
    "conv2 = conv_layer_3(conv1_pool, shape=[5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2_3(conv2)\n",
    "\n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n",
    "full_1 = tf.nn.relu(full_layer_3(conv2_flat, 1024))\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "y_conv = full_layer_3(full1_drop, 10)\n",
    "\n",
    "# Loss Function과 Train\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Accuracy 평가\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [2018-08-26 16:24:59.946351][0:00:05.955458] : Accuracy : 0.7901999950408936 \n",
      "200 [2018-08-26 16:25:16.295101][0:00:05.507338] : Accuracy : 0.884600043296814 \n",
      "300 [2018-08-26 16:25:32.311599][0:00:05.394797] : Accuracy : 0.9120000004768372 \n",
      "400 [2018-08-26 16:25:48.354734][0:00:05.332094] : Accuracy : 0.9265999794006348 \n",
      "500 [2018-08-26 16:26:04.418300][0:00:05.316938] : Accuracy : 0.9323999285697937 \n",
      "600 [2018-08-26 16:26:20.611700][0:00:05.508406] : Accuracy : 0.9333999752998352 \n",
      "700 [2018-08-26 16:26:37.277406][0:00:05.801858] : Accuracy : 0.939799964427948 \n",
      "800 [2018-08-26 16:26:53.522224][0:00:05.745081] : Accuracy : 0.9411999583244324 \n",
      "900 [2018-08-26 16:27:10.124976][0:00:06.060260] : Accuracy : 0.9478999972343445 \n",
      "1000 [2018-08-26 16:27:26.274418][0:00:05.811204] : Accuracy : 0.9510999917984009 \n",
      "1100 [2018-08-26 16:27:42.509690][0:00:05.882348] : Accuracy : 0.9542000889778137 \n",
      "1200 [2018-08-26 16:27:58.329912][0:00:05.611653] : Accuracy : 0.9550999402999878 \n",
      "1300 [2018-08-26 16:28:14.388018][0:00:05.703823] : Accuracy : 0.9581000208854675 \n",
      "1400 [2018-08-26 16:28:30.457536][0:00:05.742485] : Accuracy : 0.9595999717712402 \n",
      "1500 [2018-08-26 16:28:46.394172][0:00:05.571621] : Accuracy : 0.9581000208854675 \n",
      "1600 [2018-08-26 16:29:02.285583][0:00:05.465298] : Accuracy : 0.960800051689148 \n",
      "1700 [2018-08-26 16:29:18.091374][0:00:05.360629] : Accuracy : 0.964699923992157 \n",
      "1800 [2018-08-26 16:29:34.193464][0:00:05.238049] : Accuracy : 0.9597999453544617 \n",
      "1900 [2018-08-26 16:29:49.823970][0:00:05.174114] : Accuracy : 0.9675000309944153 \n",
      "2000 [2018-08-26 16:30:05.977167][0:00:05.194749] : Accuracy : 0.9657999873161316 \n",
      "2100 [2018-08-26 16:30:21.754195][0:00:04.803672] : Accuracy : 0.9697999954223633 \n",
      "2200 [2018-08-26 16:30:37.387548][0:00:04.642661] : Accuracy : 0.9709998965263367 \n",
      "2300 [2018-08-26 16:30:52.973029][0:00:04.682989] : Accuracy : 0.9683000445365906 \n",
      "2400 [2018-08-26 16:31:08.763533][0:00:04.931118] : Accuracy : 0.9671000242233276 \n",
      "2500 [2018-08-26 16:31:24.419559][0:00:04.626767] : Accuracy : 0.971500039100647 \n",
      "2600 [2018-08-26 16:31:40.254979][0:00:04.803965] : Accuracy : 0.9710999727249146 \n",
      "2700 [2018-08-26 16:31:55.563895][0:00:04.599091] : Accuracy : 0.9733000993728638 \n",
      "2800 [2018-08-26 16:32:10.995578][0:00:04.659191] : Accuracy : 0.9750000238418579 \n",
      "2900 [2018-08-26 16:32:26.925498][0:00:04.614772] : Accuracy : 0.9722999334335327 \n",
      "3000 [2018-08-26 16:32:42.795975][0:00:04.686094] : Accuracy : 0.9738999605178833 \n",
      "3100 [2018-08-26 16:32:58.247224][0:00:04.709589] : Accuracy : 0.9759000539779663 \n",
      "3200 [2018-08-26 16:33:14.030070][0:00:04.649130] : Accuracy : 0.9767000079154968 \n",
      "3300 [2018-08-26 16:33:29.706038][0:00:04.782783] : Accuracy : 0.9780999422073364 \n",
      "3400 [2018-08-26 16:33:45.465999][0:00:05.164134] : Accuracy : 0.9775999784469604 \n",
      "3500 [2018-08-26 16:34:01.244795][0:00:05.213067] : Accuracy : 0.9798000454902649 \n",
      "3600 [2018-08-26 16:34:17.254633][0:00:05.451136] : Accuracy : 0.9775999188423157 \n",
      "3700 [2018-08-26 16:34:33.314280][0:00:05.393524] : Accuracy : 0.9787999987602234 \n",
      "3800 [2018-08-26 16:34:49.242663][0:00:05.440638] : Accuracy : 0.9781999588012695 \n",
      "3900 [2018-08-26 16:35:05.346863][0:00:05.684824] : Accuracy : 0.9790999293327332 \n",
      "4000 [2018-08-26 16:35:22.457129][0:00:05.793551] : Accuracy : 0.9778999090194702 \n",
      "4100 [2018-08-26 16:35:38.691789][0:00:05.605101] : Accuracy : 0.9768999814987183 \n",
      "4200 [2018-08-26 16:35:54.754161][0:00:05.576585] : Accuracy : 0.9795999526977539 \n",
      "4300 [2018-08-26 16:36:10.869922][0:00:05.432080] : Accuracy : 0.9776999354362488 \n",
      "4400 [2018-08-26 16:36:26.986421][0:00:05.556027] : Accuracy : 0.9807000160217285 \n",
      "4500 [2018-08-26 16:36:43.414146][0:00:05.567910] : Accuracy : 0.9821000099182129 \n",
      "4600 [2018-08-26 16:36:59.677640][0:00:05.533106] : Accuracy : 0.9795999526977539 \n",
      "4700 [2018-08-26 16:37:15.855776][0:00:05.344723] : Accuracy : 0.9815000295639038 \n",
      "4800 [2018-08-26 16:37:31.797365][0:00:05.426461] : Accuracy : 0.9818000793457031 \n",
      "4900 [2018-08-26 16:37:47.961460][0:00:05.527023] : Accuracy : 0.9819000363349915 \n",
      "5000 [2018-08-26 16:38:01.991879][0:00:04.111136] : Accuracy : 0.9814000129699707 \n",
      "Completed !!\n"
     ]
    }
   ],
   "source": [
    "# 완전 연결 계측에서 편향을 적용하지 않은 결과\n",
    "STEPS = 5000\n",
    "X = mnist.test.images.reshape(10, 1000, 784)\n",
    "Y = mnist.test.labels.reshape(10, 1000, 10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(STEPS):\n",
    "        batch = mnist.train.next_batch(MINIBATCH_SIZE)\n",
    "        train = sess.run([x,y_, x_image, conv1, conv1_pool, conv2, conv2_pool, conv2_flat, full_1, train_step], feed_dict={x: batch[0], y_: batch[1], keep_prob:0.5})\n",
    "        if (i+1) % 100 == 0:\n",
    "            accuracy_datetime = datetime.datetime.now()\n",
    "            #print('{}[{}] : Accuracy Start '.format(i, datetime.datetime.now()))\n",
    "            train_accuracy = np.mean([sess.run([accuracy], feed_dict={x: X[j], y_: Y[j], keep_prob: 1.0}) for j in range(10)])\n",
    "            print('{} [{}][{}] : Accuracy : {} '.format(i+1, datetime.datetime.now(), datetime.datetime.now() - accuracy_datetime, train_accuracy))\n",
    "    print('Completed !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
