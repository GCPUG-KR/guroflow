{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-536d0be4f0e2>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting save_dir_8_4/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting save_dir_8_4/train-labels-idx1-ubyte.gz\n",
      "Extracting save_dir_8_4/t10k-images-idx3-ubyte.gz\n",
      "Extracting save_dir_8_4/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "<class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'>\n",
      "[0]<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f1efc558e48>\n",
      "[1]<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f1efc4f4358>\n",
      "[2]<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f1efc4f40f0>\n",
      "[0].image.shape:(59000, 28, 28, 1)\n",
      "    labels.shape:(59000,)\n",
      "[1].image.shape:(1000, 28, 28, 1)\n",
      "    labels.shape:(1000,)\n",
      "[2].image.shape:(10000, 28, 28, 1)\n",
      "    labels.shape:(10000,)\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"save_dir_8_4\"\n",
    "save_dir_tfrecord = \"save_dir_8_4_tfrecord\"\n",
    "\n",
    "# Download data to save_Dir\n",
    "data_sets = mnist.read_data_sets(save_dir,\n",
    "                                 dtype=tf.uint8,\n",
    "                                 reshape=False,\n",
    "                                 validation_size=1000)\n",
    "print('{}\\n[0]{}\\n[1]{}\\n[2]{}'.format(type(data_sets),data_sets[0],data_sets[1],data_sets[2]))\n",
    "print('[0].image.shape:{}\\n    labels.shape:{}'.format(data_sets[0].images.shape,data_sets[0].labels.shape))\n",
    "print('[1].image.shape:{}\\n    labels.shape:{}'.format(data_sets[1].images.shape,data_sets[1].labels.shape))\n",
    "print('[2].image.shape:{}\\n    labels.shape:{}'.format(data_sets[2].images.shape,data_sets[2].labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "saving train\n",
      "Loop(0) filename : save_dir_8_4_tfrecord/train.tfrecords\n",
      "     >> type(example.features.feature['image_row']) : <class 'tensorflow.core.example.feature_pb2.Feature'>\n",
      "     >> type(image) : <class 'bytes'>   |   len(image) : 784\n",
      "     >> Loop(0) Complete!\n",
      "****************************************************************************************************\n",
      "saving test\n",
      "Loop(1) filename : save_dir_8_4_tfrecord/test.tfrecords\n",
      "     >> Loop(1) Complete!\n",
      "****************************************************************************************************\n",
      "saving validation\n",
      "Loop(2) filename : save_dir_8_4_tfrecord/validation.tfrecords\n",
      "     >> Loop(2) Complete!\n",
      "****************************************************************************************************\n",
      "complete!\n"
     ]
    }
   ],
   "source": [
    "print_onoff = 0\n",
    "data_splits = [\"train\",\"test\",\"validation\"]\n",
    "for d in range(len(data_splits)):\n",
    "    print('*'*100)\n",
    "    print(\"saving \"+data_splits[d])\n",
    "    data_set = data_sets[d]\n",
    "    filename = os.path.join(save_dir_tfrecord, data_splits[d] + '.tfrecords')\n",
    "    print('Loop({}) filename : {}'.format(d, filename))\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(data_set.images.shape[0]):\n",
    "        image = data_set.images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature={\n",
    "                'height': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(value=[data_set.images.shape[1]])),     # 실데이터가 아닌, image_row의 height Meta값을 저장한다.\n",
    "                'width': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(value=[data_set.images.shape[2]])),     # 실데이터가 아닌, image_row의 width Meta값을 저장한다.\n",
    "                'depth': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(value=[data_set.images.shape[3]])),     # 실데이터가 아닌, image_row의 depth Meta값을 저장한다.\n",
    "                'label': tf.train.Feature(\n",
    "                    int64_list=tf.train.Int64List(value=[int(data_set.labels[index])])),  # label의 실제값을 저장한다.\n",
    "                'image_raw': tf.train.Feature(\n",
    "                    bytes_list=tf.train.BytesList(value=[image]))}))                      # image의 실제값을 저장하다.\n",
    "        print_onoff += 1\n",
    "        if print_onoff == 1:\n",
    "            #print(\"     >> type(example.features.feature) : {}\\n     >> example.features.feature['height'] : {}\".format(type(example.features.feature),example.features.feature[\"height\"]))\n",
    "            print(\"     >> type(example.features.feature['image_row']) : {}\".format(type(example.features.feature['image_raw'])))\n",
    "            print(\"     >> type(image) : {}   |   len(image) : {}\".format(type(image),len(image)))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('     >> Loop({}) Complete!'.format(d))\n",
    "print('*'*100)\n",
    "print('complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "filename = os.path.join(save_dir_tfrecord, \"train.tfrecords\")\n",
    "filename_queue = tf.train.string_input_producer([filename], num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "image.set_shape([784])\n",
    "image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "label = tf.cast(features['label'], tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"shuffle_batch_1:0\", shape=(128, 784), dtype=float32) Tensor(\"shuffle_batch_1:1\", shape=(128,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the examples + batch\n",
    "images_batch, labels_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=128,\n",
    "    capacity=2000,\n",
    "    min_after_dequeue=1000)\n",
    "print('{} {}'.format(images_batch, labels_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('W', reuse=tf.AUTO_REUSE):\n",
    "    W = tf.get_variable(\"W\", [28*28, 10])\n",
    " \n",
    "    y_pred = tf.matmul(images_batch, W)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred, labels=labels_batch)\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "init = tf.local_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) : <Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, started daemon 139769503807232)>\n",
      "(1) : <Thread(QueueRunnerThread-input_producer-close_on_stop, started daemon 139769495414528)>\n",
      "(2) : <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 139769463961344)>\n",
      "(3) : <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-close_on_stop, started daemon 139769927431936)>\n",
      "(4) : <Thread(QueueRunnerThread-input_producer_1-input_producer_1/input_producer_1_EnqueueMany, started daemon 139770594957056)>\n",
      "(5) : <Thread(QueueRunnerThread-input_producer_1-close_on_stop, started daemon 139769971472128)>\n",
      "(6) : <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-shuffle_batch_1/random_shuffle_queue_enqueue, started daemon 139769963079424)>\n",
      "(7) : <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-close_on_stop, started daemon 139769950500608)>\n"
     ]
    }
   ],
   "source": [
    "# coordinator\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "for i in range(len(threads)):\n",
    "    print('({}) : {}'.format(i,threads[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:       500 ,  loss_mean_val : [0.41213182]\n",
      "step:      1000 ,  loss_mean_val : [0.3878948]\n",
      "step:      1500 ,  loss_mean_val : [0.37645757]\n",
      "step:      2000 ,  loss_mean_val : [0.33515334]\n",
      "step:      2500 ,  loss_mean_val : [0.34799904]\n",
      "step:      3000 ,  loss_mean_val : [0.41444105]\n",
      "step:      3500 ,  loss_mean_val : [0.24963039]\n",
      "step:      4000 ,  loss_mean_val : [0.41639793]\n",
      "step:      4500 ,  loss_mean_val : [0.30804473]\n",
      "Done training for 10 epochs, 4601 steps.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    step = 0\n",
    "    while not coord.should_stop():\n",
    "        step += 1\n",
    "        sess.run([train_op])\n",
    "        if step % 500 == 0:\n",
    "            loss_mean_val = sess.run([loss_mean])\n",
    "            print('step:{:10} ,  loss_mean_val : {}'.format(step,loss_mean_val))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training for %d epochs, %d steps.' % (NUM_EPOCHS, step))\n",
    "finally:\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "\n",
    "coord.join(threads)\n",
    "sess.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
