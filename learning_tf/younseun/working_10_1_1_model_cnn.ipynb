{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import os \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_cnn:\n",
    "    def __init__(self, x_image,keep_prob, weights=None, sess=None):\n",
    "        \n",
    "        self.parameters = []\n",
    "        self.x_image = x_image\n",
    "\n",
    "        conv1 = self.conv_layer(x_image, shape=[5, 5, 1, 32])\n",
    "        conv1_pool = self.max_pool_2x2(conv1)\n",
    "\n",
    "        conv2 = self.conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
    "        conv2_pool = self.max_pool_2x2(conv2)\n",
    "\n",
    "        conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n",
    "        full_1 = tf.nn.relu(self.full_layer(conv2_flat, 1024))\n",
    "\n",
    "        full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "        self.y_conv = self.full_layer(full1_drop, 10)\n",
    "        \n",
    "        if weights is not None and sess is not None:\n",
    "            self.load_weights(weights, sess)\n",
    "            \n",
    "    def weight_variable(self,shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(initial,name='weights')\n",
    "\n",
    "\n",
    "    def bias_variable(self,shape):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(initial,name='biases')\n",
    "\n",
    "\n",
    "    def conv2d(self,x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], \n",
    "                                       padding='SAME')\n",
    "\n",
    "\n",
    "    def max_pool_2x2(self,x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "    def conv_layer(self,input, shape):\n",
    "        W = self.weight_variable(shape)\n",
    "        b = self.bias_variable([shape[3]])\n",
    "        self.parameters += [W, b]\n",
    "\n",
    "        return tf.nn.relu(self.conv2d(input, W) + b)\n",
    "\n",
    "\n",
    "    def full_layer(self,input, size):\n",
    "        in_size = int(input.get_shape()[1])\n",
    "        W = self.weight_variable([in_size, size])\n",
    "        b = self.bias_variable([size])\n",
    "        self.parameters += [W, b]\n",
    "        return tf.matmul(input, W) + b\n",
    "    \n",
    "\n",
    "    def load_weights(self, weights, sess):\n",
    "        for i,w in enumerate(weights):\n",
    "            print(\"Weight index: {}\".format(i), \n",
    "                               \"Weight shape: {}\".format(w.shape))\n",
    "            sess.run(self.parameters[i].assign(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "NUM_STEPS : (0)   accuracy:0.05999999865889549\n",
      "NUM_STEPS : (100)   accuracy:0.7900000214576721\n",
      "NUM_STEPS : (200)   accuracy:0.9399999976158142\n",
      "NUM_STEPS : (300)   accuracy:0.8600000143051147\n",
      "NUM_STEPS : (400)   accuracy:0.9700000286102295\n",
      "NUM_STEPS : (500)   accuracy:0.9599999785423279\n",
      "NUM_STEPS : (600)   accuracy:0.9800000190734863\n",
      "NUM_STEPS : (700)   accuracy:0.9599999785423279\n",
      "NUM_STEPS : (800)   accuracy:0.9599999785423279\n",
      "NUM_STEPS : (900)   accuracy:0.9399999976158142\n",
      "test accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/tmp/data'\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100\n",
    "epochs=10\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "sess = tf.Session()\n",
    "cnn = simple_cnn(x_image,keep_prob, sess)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=cnn.y_conv, labels= y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(cnn.y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "X = data.test.images.reshape(10, 1000, 784)\n",
    "Y = data.test.labels.reshape(10, 1000, 10)\n",
    "for j in range(NUM_STEPS):\n",
    "    batch_xs, batch_ys = data.train.next_batch(MINIBATCH_SIZE)\n",
    "    _, acc = sess.run([train_step,accuracy], feed_dict={x:batch_xs, y_:batch_ys ,keep_prob:1.0})\n",
    "    if j % 100 == 0:\n",
    "        print('NUM_STEPS : ({:5})   accuracy:{}'.format(j, acc))\n",
    "test_accuracy = np.mean([sess.run(accuracy, \n",
    "                         feed_dict={x:X[i], y_:Y[i],keep_prob:1.0}) \n",
    "                         for i in range(10)])    \n",
    "path = './model/'\n",
    "weights = sess.run(cnn.parameters)\n",
    "np.savez(os.path.join(path, 'cnn_weight_storage'), weights)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight index: 0 Weight shape: (5, 5, 1, 32)\n",
      "Weight index: 1 Weight shape: (32,)\n",
      "Weight index: 2 Weight shape: (5, 5, 32, 64)\n",
      "Weight index: 3 Weight shape: (64,)\n",
      "Weight index: 4 Weight shape: (3136, 1024)\n",
      "Weight index: 5 Weight shape: (1024,)\n",
      "Weight index: 6 Weight shape: (1024, 10)\n",
      "Weight index: 7 Weight shape: (10,)\n",
      "test accuracy: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "sess = tf.Session()\n",
    "\n",
    "weights = np.load(path+'cnn_weight_storage.npz')\n",
    "weights = weights.items()[0][1]\n",
    "cnn = simple_cnn(x_image,keep_prob, weights, sess)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=cnn.y_conv, labels= y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(cnn.y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "X = data.test.images.reshape(10, 1000, 784)\n",
    "Y = data.test.labels.reshape(10, 1000, 10)\n",
    "\n",
    "test_accuracy = np.mean([sess.run(accuracy, \n",
    "                         feed_dict={x:X[i], y_:Y[i],keep_prob:1.0}) \n",
    "                         for i in range(10)])    \n",
    "print(\"test accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
