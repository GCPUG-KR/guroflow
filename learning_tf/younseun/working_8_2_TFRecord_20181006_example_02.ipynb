{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"save_dir\"\n",
    "save_dir_TFRecord_01 = \"save_dir_TFRecord_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting save_dir/train-images-idx3-ubyte.gz\n",
      "Extracting save_dir/train-labels-idx1-ubyte.gz\n",
      "Extracting save_dir/t10k-images-idx3-ubyte.gz\n",
      "Extracting save_dir/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#save_dir 에 데이터 내려받기\n",
    "data_sets = mnist.read_data_sets(save_dir, \n",
    "                                 dtype=tf.uint8,\n",
    "                                reshape=False,\n",
    "                                validation_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.train     ].image.shape:(59000, 28, 28, 1)    labels.shape:(59000,)\n",
      "[1.validation].image.shape:(1000, 28, 28, 1)    labels.shape:(1000,)\n",
      "[2.test      ].image.shape:(10000, 28, 28, 1)    labels.shape:(10000,)\n"
     ]
    }
   ],
   "source": [
    "print('[0.train     ].image.shape:{}    labels.shape:{}'.format(data_sets[0].images.shape,data_sets[0].labels.shape))\n",
    "print('[1.validation].image.shape:{}    labels.shape:{}'.format(data_sets[1].images.shape,data_sets[1].labels.shape))\n",
    "print('[2.test      ].image.shape:{}    labels.shape:{}'.format(data_sets[2].images.shape,data_sets[2].labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# row 한개씩 추가로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename : save_dir_TFRecord_01/train_record.tfrecords\n",
      ">>  0 \n",
      "complete!\n"
     ]
    }
   ],
   "source": [
    "# row 한개씩 추가로 저장하기\n",
    "print_onoff = 0\n",
    "data_set = data_sets[0]\n",
    "filename = os.path.join(save_dir_TFRecord_01, 'train_record.tfrecords')\n",
    "print('filename : {}'.format(filename))\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "#for index in range(data_set.images.shape[0]):\n",
    "for index in range(10):\n",
    "    image = data_set.images[index].tostring()\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature={\n",
    "            'height': tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=[data_set.images.shape[1]])),     # 실데이터가 아닌, image_row의 height Meta값을 저장한다.\n",
    "            'width': tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=[data_set.images.shape[2]])),     # 실데이터가 아닌, image_row의 width Meta값을 저장한다.\n",
    "            'depth': tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=[data_set.images.shape[3]])),     # 실데이터가 아닌, image_row의 depth Meta값을 저장한다.\n",
    "            'label': tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=[int(data_set.labels[index])])),  # label의 실제값을 저장한다.\n",
    "            'image_raw': tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=[image]))}))                      # image의 실제값을 저장하다.\n",
    "    print_onoff += 1\n",
    "    if (print_onoff % 10000) == 1:\n",
    "        print(\">>  {} \".format(index))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()\n",
    "\n",
    "print('complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(example.features.feature[\"height\"].int64_list.value[0])\n",
    "print(example.features.feature[\"width\"].int64_list.value[0])\n",
    "print(example.features.feature[\"depth\"].int64_list.value[0])\n",
    "print(example.features.feature[\"label\"].int64_list.value[0])\n",
    "#print(example.features.feature[\"image_raw\"].bytes_list.value[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# row 한개씩 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 형태로 저장된 파일에서 1건씩 불러오는 과정\n",
    "filename = os.path.join(save_dir_TFRecord_01, 'train_record.tfrecords')\n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "example = tf.train.Example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "first = 0\n",
    "image_list = [];label_list = [];width_list = [];height_list = [];\n",
    "for seralized_img_example in record_iterator:\n",
    "    first += 1\n",
    "    example.ParseFromString(seralized_img_example)\n",
    "    image_list.append(np.fromstring(example.features.feature['image_raw'].bytes_list.value[0], dtype=np.uint8).reshape((28, 28, -1)))\n",
    "    label_list.append(example.features.feature['label'].int64_list.value[0])\n",
    "    width_list.append(example.features.feature['width'].int64_list.value[0])\n",
    "    height_list.append(example.features.feature['height'].int64_list.value[0])\n",
    "image = np.array(image_list)\n",
    "label = np.array(label_list)\n",
    "width = np.array(width_list)\n",
    "height = np.array(height_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 28, 28, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배열 한꺼번에 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet at 0x7f8b8cb7dc88>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename : save_dir_TFRecord_01/train_array.tfrecords\n"
     ]
    }
   ],
   "source": [
    "print_onoff = 0\n",
    "data_set = data_sets[0]\n",
    "filename_array = os.path.join(save_dir_TFRecord_01, 'train_array.tfrecords')\n",
    "print('filename : {}'.format(filename))\n",
    "writer_array = tf.python_io.TFRecordWriter(filename_array)\n",
    "\n",
    "label_bytes= data_set.labels[:10].tostring()\n",
    "image_bytes= data_set.images[:10].tostring()\n",
    "image_cnt = data_set.images[:10].shape[0]\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "\n",
    "example_array = tf.train.Example(features=tf.train.Features(feature={\n",
    " 'label': tf.train.Feature(bytes_list=tf.train.BytesList(value=[label_bytes])),\n",
    " 'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes])),\n",
    " 'cnt': tf.train.Feature(int64_list=tf.train.Int64List(value=[image_cnt])), \n",
    " 'width': tf.train.Feature(int64_list=tf.train.Int64List(value=[image_width])), \n",
    " 'height': tf.train.Feature(int64_list=tf.train.Int64List(value=[image_height])), \n",
    " }))\n",
    "\n",
    "\n",
    "writer_array.write(example_array.SerializeToString())\n",
    "writer_array.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한번에 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 형태로 저장된 파일에서 1건씩 불러오는 과정\n",
    "filename = os.path.join(save_dir_TFRecord_01, 'train_array.tfrecords')\n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "seralized_img_example = next(record_iterator)\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(seralized_img_example)\n",
    "\n",
    "image = np.fromstring(example.features.feature['image_raw'].bytes_list.value[0], dtype=np.uint8).reshape(10,28,28,1)\n",
    "label = np.fromstring(example.features.feature['label'].bytes_list.value[0], dtype=np.uint8)\n",
    "cnt = example.features.feature['cnt'].int64_list.value[0]\n",
    "width = example.features.feature['width'].int64_list.value[0]\n",
    "height = example.features.feature['height'].int64_list.value[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
