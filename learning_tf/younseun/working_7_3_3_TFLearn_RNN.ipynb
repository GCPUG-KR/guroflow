{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000,\n",
    "                                valid_portion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "[17, 25, 10, 406, 26, 14, 56, 61, 62, 323, 4]\n",
      "[16, 586, 32, 885, 17, 39, 68, 31, 2994, 2389, 328, 4]\n",
      "[1, 2, 1, 139, 6, 130, 1, 5, 6, 25, 105, 4730, 40]\n",
      "[30, 287, 142, 2216, 707, 3763, 20, 68, 57, 30, 37, 309, 14, 4]\n",
      "[6691, 1, 10, 333, 10, 17, 27, 4, 34, 181, 6, 1418, 256, 4]\n",
      "****************************************************************************************************\n",
      "2500\n",
      "[69, 519, 25, 4, 59, 6, 100, 76, 17, 77, 21, 4, 16, 287, 54, 49, 8, 38, 516, 8, 814, 6, 1033, 7, 14, 26, 17, 139, 33, 320, 620, 4]\n",
      "[221, 890, 3, 2, 262, 3042, 27, 140, 107, 4, 2, 25, 2196, 41, 3641, 22, 1853, 3, 394, 3, 5, 2850, 4, 121, 3042, 20, 2457, 663, 1402, 482, 2, 27, 4]\n",
      "[1463, 1, 1, 15, 873, 60, 59, 21, 15, 18, 3129, 60, 6, 406, 25, 3, 26, 1307, 4, 16, 133, 2, 2496, 3619, 1, 646, 205, 4, 3129, 88, 3662, 175, 30, 79, 17, 25, 4]\n",
      "[16, 436, 2, 25, 6, 165, 189, 4, 483, 8, 79, 14, 54, 23, 1, 1, 3, 26, 2, 131, 5, 76, 82, 618, 113, 4, 6, 67, 664, 663, 15, 131, 65, 30, 238, 539, 14, 4]\n",
      "[17, 10, 6, 51, 8720, 51, 4, 14, 1, 4550, 1794, 4, 2, 131, 10, 6584, 5, 494, 6534, 4, 2, 294, 93, 2604, 30, 260, 4, 12, 13, 9, 11, 12, 13, 9, 11, 79, 14, 1904, 30, 37, 2, 1405, 4]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = train\n",
    "X_test, Y_test = test\n",
    "print(len(X_train))\n",
    "print(X_train[0])\n",
    "print(X_train[1])\n",
    "print(X_train[2])\n",
    "print(X_train[3])\n",
    "print(X_train[4])\n",
    "print('*'*100)\n",
    "print(len(X_test))\n",
    "print(X_test[0])\n",
    "print(X_test[1])\n",
    "print(X_test[2])\n",
    "print(X_test[3])\n",
    "print(X_test[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence padding and Converting labels to binary vectors\n",
    "X_train = pad_sequences(X_train, maxlen=100, value=0.)\n",
    "X_test = pad_sequences(X_test, maxlen=100, value=0.)\n",
    "Y_train = to_categorical(Y_train, nb_classes=2)\n",
    "Y_test = to_categorical(Y_test, nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  25  10 406  26  14  56  61  62 323   4   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n",
      "[  16  586   32  885   17   39   68   31 2994 2389  328    4    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "****************************************************************************************************\n",
      "[  69  519   25    4   59    6  100   76   17   77   21    4   16  287\n",
      "   54   49    8   38  516    8  814    6 1033    7   14   26   17  139\n",
      "   33  320  620    4    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[ 221  890    3    2  262 3042   27  140  107    4    2   25 2196   41\n",
      " 3641   22 1853    3  394    3    5 2850    4  121 3042   20 2457  663\n",
      " 1402  482    2   27    4    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(X_train[1])\n",
    "print('*'*100)\n",
    "print(X_test[0])\n",
    "print(X_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Building a LSTM network\n",
    "RNN = tflearn.input_data([None, 100])\n",
    "RNN = tflearn.embedding(RNN, input_dim=10000, output_dim=128)   # 차원 embedding\n",
    "\n",
    "RNN = tflearn.lstm(RNN, 128, dropout=0.8)\n",
    "RNN = tflearn.fully_connected(RNN, 2, activation='softmax')\n",
    "RNN = tflearn.regression(RNN, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7039  | total loss: \u001b[1m\u001b[32m0.04515\u001b[0m\u001b[0m | time: 126.545s\n",
      "| Adam | epoch: 010 | loss: 0.04515 - acc: 0.9855 -- iter: 22496/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.04161\u001b[0m\u001b[0m | time: 130.321s\n",
      "| Adam | epoch: 010 | loss: 0.04161 - acc: 0.9870 | val_loss: 0.83737 - val_acc: 0.8056 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "model = tflearn.DNN(RNN, tensorboard_verbose=0)\n",
    "model.fit(X_train, Y_train, validation_set=(X_test, Y_test),\n",
    "                                show_metric=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
